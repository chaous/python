# Инструкция по настройке проекта для парсинга веб-сайтов

Данный проект использует модули `requests` и `BeautifulSoup4` для получения и парсинга данных с веб-сайта. Инструкция поможет настроить виртуальное окружение и выполнить скрипт для парсинга.

## Шаг 1: Создание виртуального окружения

1. Перейдите в директорию вашего проекта.
2. Создайте виртуальное окружение с помощью команды:
   ```bash
   python3 -m venv venv
   ```
   Это создаст папку `venv`, содержащую изолированное окружение для проекта.

3. Активируйте виртуальное окружение:
   - На Windows: `venv\Scripts\activate`
   - На macOS и Linux: `source venv/bin/activate`

## Шаг 2: Установка необходимых модулей

После активации виртуального окружения установите модули `requests` и `BeautifulSoup4`:
   ```bash
   pip install requests beautifulsoup4
   ```

## Шаг 3: Создание скрипта для получения и парсинга данных

Создайте файл `web_scraper.py` в рабочей директории и добавьте следующий код:
   ```python
   import requests
   from bs4 import BeautifulSoup

   def fetch_and_parse(url):
       try:
           # Получаем HTML-данные с веб-сайта
           response = requests.get(url)
           response.raise_for_status()  # Проверяем успешность запроса
           
           # Парсим HTML-код
           soup = BeautifulSoup(response.text, 'html.parser')
           
           # Пример: Извлекаем заголовок страницы
           title = soup.title.string if soup.title else "Заголовок не найден"
           print(f"Заголовок страницы: {title}")
           
           # Пример: Извлекаем все ссылки на странице
           links = [a['href'] for a in soup.find_all('a', href=True)]
           print("Ссылки на странице:")
           for link in links:
               print(link)
               
       except requests.exceptions.RequestException as e:
           print(f"Ошибка при получении данных: {e}")

   # URL для парсинга
   url = "https://www.example.com"  # Замените на любой сайт для тестирования
   fetch_and_parse(url)
   ```

## Шаг 4: Запуск скрипта

Убедитесь, что виртуальное окружение активировано, и запустите скрипт:
   ```bash
   python web_scraper.py
   ```
После запуска скрипта вы увидите заголовок страницы и список всех ссылок, найденных на указанной странице.

## Шаг 5: Деактивация виртуального окружения

После завершения работы над проектом деактивируйте виртуальное окружение:
   ```bash
   deactivate
   ```

## Примечание

Этот проект работает в изолированном виртуальном окружении, чтобы избежать влияния на глобальные установки Python. Убедитесь, что вы активировали виртуальное окружение перед запуском скрипта, чтобы использовать установленные зависимости только в рамках проекта.
